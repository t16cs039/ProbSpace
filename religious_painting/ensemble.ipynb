{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"ensemble.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1wn8xU5f0MpDCXNSPNeU9JEF7Nas6P2Xc","authorship_tag":"ABX9TyMhsCFsrDwdmdbtHsezQ0lr"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"zPtK-L8QnXtt"},"source":["# Preparing data"]},{"cell_type":"code","metadata":{"id":"Grb_UYRU8g0L"},"source":["import numpy as np\n","from tensorflow.keras.utils import to_categorical"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UEhyBjrT8rd2"},"source":["## Loading data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-3uoMmU-8g2p","executionInfo":{"status":"ok","timestamp":1629202372015,"user_tz":-540,"elapsed":404,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNZwF47kdODsd-L18SA_WiFr15RB65RBmwXBlp=s64","userId":"05018280988882150099"}},"outputId":"223e11f5-dee5-4cd1-b96c-73641958a5f8"},"source":["train_data = np.load('/content/drive/MyDrive/ProbSpace/宗教画テーマの分類/dataset/christ-train-imgs.npz')['arr_0']\n","train_label = np.load('/content/drive/MyDrive/ProbSpace/宗教画テーマの分類/dataset/christ-train-labels.npz')['arr_0']\n","test_data = np.load('/content/drive/MyDrive/ProbSpace/宗教画テーマの分類/dataset/christ-test-imgs.npz')['arr_0']\n","\n","print('train_data shape: {0}'.format(train_data.shape))\n","print('test_data shape: {0}'.format(test_data.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_data shape: (654, 224, 224, 3)\n","test_data shape: (497, 224, 224, 3)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"aU3X5jv68t5h"},"source":["## one hot encoding label data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lT6h69rrlwqN","executionInfo":{"status":"ok","timestamp":1629202372015,"user_tz":-540,"elapsed":5,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNZwF47kdODsd-L18SA_WiFr15RB65RBmwXBlp=s64","userId":"05018280988882150099"}},"outputId":"e62f90d4-687e-45c5-e1a4-06ef4223fbc9"},"source":["train_label = to_categorical(train_label)\n","\n","print('train_label shape: {0}'.format(train_label.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_label shape: (654, 13)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"zTLLmxnbT3nM"},"source":["# Preprocessing"]},{"cell_type":"code","metadata":{"id":"ZTDhSkI885ml"},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JeFPDvR2_x1Z"},"source":["## ImageDataGenerator"]},{"cell_type":"code","metadata":{"id":"MMDaOJ3uDgDM"},"source":["datagen = ImageDataGenerator(featurewise_center=False, \n","                             samplewise_center=False,\n","                             featurewise_std_normalization=False, \n","                             samplewise_std_normalization=False,\n","                             zca_whitening=False, \n","                             zca_epsilon=1e-06, \n","                             rotation_range=0, \n","                             width_shift_range=0.0,\n","                             height_shift_range=0.0, \n","                             brightness_range=None, \n","                             shear_range=0.0, \n","                             zoom_range=0.0,\n","                             channel_shift_range=0.0, \n","                             fill_mode='nearest', \n","                             cval=0.0,\n","                             horizontal_flip=False, \n","                             vertical_flip=False, \n","                             rescale=1./255.,\n","                             preprocessing_function=None, \n","                             data_format=None, \n","                             validation_split=0.0, \n","                             dtype=None)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Dpla6-ET_Yew"},"source":["test_generator = datagen.flow(test_data,\n","                              batch_size=4, \n","                              shuffle=False, \n","                              sample_weight=None, \n","                              seed=None,\n","                              save_to_dir=None, \n","                              save_prefix='', \n","                              save_format='png',\n","                              subset=None,)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"z_JBHtBw96if"},"source":["# Function"]},{"cell_type":"markdown","metadata":{"id":"_iZGYBzc1nqI"},"source":["## Creating model"]},{"cell_type":"code","metadata":{"id":"eLGNXEasyCJi"},"source":["!pip install --quiet tensorflow_addons\n","!pip install --quiet vit-keras\n","!pip install --quiet mlp-mixer-keras"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"6YId9oWm_d9u"},"source":["from tensorflow.keras.applications import VGG16, ResNet50, EfficientNetB0\n","from tensorflow.keras.layers import Input, GlobalAveragePooling2D, Dense, BatchNormalization, LeakyReLU, Activation\n","from tensorflow.keras.models import Model, Sequential\n","from tensorflow.keras.optimizers.schedules import CosineDecay\n","from tensorflow.keras.optimizers import Adam, SGD\n","from tensorflow_addons.losses import SigmoidFocalCrossEntropy\n","from vit_keras import vit, utils\n","from mlp_mixer_keras import MlpMixerModel"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mgV6BC2M0evO"},"source":["### creating vgg model"]},{"cell_type":"code","metadata":{"id":"23MkmU9C0gzU"},"source":["def creating_vgg_model():\n","\n","  input = Input(shape=(224, 224, 3))\n","\n","  conv_base = VGG16(include_top=False, \n","                    weights='imagenet', \n","                    input_tensor=input)\n"," \n","  _ = GlobalAveragePooling2D()(conv_base.output)\n","  \n","  _ = Dense(13)(_)\n","  \n","  output = Activation('softmax')(_)\n","\n","  model = Model(inputs=[input], outputs=[output])\n","  \n","  model.compile(optimizer=Adam(learning_rate=1e-5),\n","                loss=SigmoidFocalCrossEntropy(),\n","                metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jTmPSr_ScbnW"},"source":["### creating resnet model"]},{"cell_type":"code","metadata":{"id":"PDhu7JbPcbum"},"source":["def creating_resnet_model():\n","\n","  input = Input(shape=(224, 224, 3))\n","\n","  conv_base = ResNet50(include_top=False, \n","                       weights='imagenet', \n","                       input_tensor=input)\n","  \n","  _ = conv_base(input)\n","\n","  _ = GlobalAveragePooling2D()(_)\n","  \n","  _ = Dense(13)(_)\n","  \n","  output = Activation('softmax')(_)\n","\n","  model = Model(inputs=[input], outputs=[output])\n","  \n","  model.compile(optimizer=Adam(learning_rate=1e-5),\n","                loss=SigmoidFocalCrossEntropy(),\n","                metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iJyC0tugornh"},"source":["### creating efficient model"]},{"cell_type":"code","metadata":{"id":"K7PGIsWImT8Q"},"source":["def creating_efficient_model():\n","\n","  input = Input(shape=(224, 224, 3))\n","\n","  conv_base = EfficientNetB0(include_top=False, \n","                             weights='imagenet', \n","                             input_tensor=input)\n","  \n","  _ = GlobalAveragePooling2D()(conv_base.output)\n","  \n","  _ = Dense(13)(_)\n","  \n","  output = Activation('softmax')(_)\n","\n","  model = Model(inputs=[input], outputs=[output])\n","  \n","  model.compile(optimizer=Adam(learning_rate=1e-5),\n","                loss=SigmoidFocalCrossEntropy(),\n","                metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pD8ayu_2ouKh"},"source":["### creating vit model\n","\n","[pip install vit-keras](https://pypi.org/project/vit-keras/)"]},{"cell_type":"code","metadata":{"id":"cDt9n6tpl4mN"},"source":["def creating_vit_model():\n","\n","  model = Sequential()\n","\n","  # vit_b16, vit_b32, vit_l16, vit_l32 #\n","  model.add(vit.vit_b16(image_size=224, \n","                        activation='sigmoid',\n","                        pretrained=True, \n","                        include_top=True, \n","                        pretrained_top=False, \n","                        classes=13,))\n","  \n","  model.add(Activation('softmax'))\n","  \n","  model.compile(optimizer=Adam(learning_rate=1e-5),\n","                loss=SigmoidFocalCrossEntropy(),\n","                metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7AhkLJKjpXKk"},"source":["### creating mlp mixer model\n","\n","[pip install mpl-mixer-keras](https://pypi.org/project/mlp-mixer-keras/)\n","\n","[reference parameter](https://qiita.com/T-STAR/items/dcaa7873a6d193912ed1)"]},{"cell_type":"code","metadata":{"id":"IVvzu1p3pXRs"},"source":["def creating_mlp_mixer_model():\n","\n","  model = MlpMixerModel(input_shape=(224, 224, 3),\n","                        num_classes=13, \n","                        num_blocks=4, \n","                        patch_size=8,\n","                        hidden_dim=32,\n","                        tokens_mlp_dim=64,\n","                        channels_mlp_dim=128,\n","                        use_softmax=True)\n","\n","  model.compile(optimizer=Adam(learning_rate=1e-5),\n","                loss=SigmoidFocalCrossEntropy(),\n","                metrics=['accuracy'])\n","\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lo3Q4JML1i69"},"source":["## Ensemble"]},{"cell_type":"code","metadata":{"id":"gHbM-CY1Anjj"},"source":["from sklearn.model_selection import StratifiedKFold\n","import numpy as np\n","from keras.callbacks import ModelCheckpoint\n","from keras.models import load_model\n","from sklearn.metrics import accuracy_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"yjDB02LB1jH8"},"source":["def cross_val_score_for_ensemble(X_train, Y_train, epochs, batch_size, model_path, n_splits=10):\n","\n","  skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=2021)\n","\n","  scores = []\n","  num = 0\n","\n","  for train_idx, val_idx in skf.split(X_train, Y_train.argmax(axis=1)):\n","    \n","    train_data_for_generator, train_label_for_generator, val_data_for_generator, val_label_for_generator = X_train[train_idx], Y_train[train_idx], X_train[val_idx], Y_train[val_idx]\n","\n","    train_generator = datagen.flow(train_data_for_generator, train_label_for_generator,\n","                                   batch_size=4, \n","                                   shuffle=True, \n","                                   sample_weight=None,\n","                                   seed=2021,\n","                                   save_to_dir=None, \n","                                   save_prefix='', \n","                                   save_format='png',\n","                                   subset=None,)\n","    \n","    val_generator = datagen.flow(val_data_for_generator, val_label_for_generator,\n","                                 batch_size=4, \n","                                 shuffle=False, \n","                                 sample_weight=None, \n","                                 seed=2021,\n","                                 save_to_dir=None, \n","                                 save_prefix='', \n","                                 save_format='png',\n","                                 subset=None,)\n","\n","    # model = creating_vgg_model()\n","    # model = creating_resnet_model()\n","    # model = creating_efficient_model()\n","    model = creating_vit_model()\n","    # model = creating_mlp_mixer_model()\n","    callbacks_list = [ModelCheckpoint(filepath=str(num)+model_path, monitor='val_accuracy', save_best_only=True),]\n","    history = model.fit(train_generator, \n","                        epochs=epochs, \n","                        batch_size=batch_size, \n","                        callbacks=callbacks_list, \n","                        verbose=0, \n","                        validation_data=val_generator)\n","    model.load_weights(str(num)+model_path)\n","    num += 1\n","    score = accuracy_score(np.argmax(val_label_for_generator, axis=1), np.argmax(model.predict(val_generator), axis=1))\n","    scores.append(score)\n","    print('accuracy: {0:.3f}'.format(score))\n","\n","  return scores"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"D9uEQA8dArZV"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"DDA-ewRnAtpF"},"source":["from time import time"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uVL2xVnE7N0Z","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629212182965,"user_tz":-540,"elapsed":9802759,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNZwF47kdODsd-L18SA_WiFr15RB65RBmwXBlp=s64","userId":"05018280988882150099"}},"outputId":"5b5d3746-97c4-41d4-f744-50b7c0db4772"},"source":["EPOCHS = 100\n","BATCH_SIZE = 4\n","\n","start_time = time()\n","acc = cross_val_score_for_ensemble(train_data, train_label, EPOCHS, BATCH_SIZE, 'model.h5', 5)\n","elapsed_time = time() - start_time\n","\n","print('Elapsed time: {0:.3f} hrs'.format(elapsed_time / 3600))\n","print('Mean accuracy for cv: {0:.3f}'.format(np.mean(acc)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading data from https://github.com/faustomorales/vit-keras/releases/download/dl/ViT-B_16_imagenet21k+imagenet2012.npz\n","347504640/347502902 [==============================] - 6s 0us/step\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n","  UserWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["accuracy: 0.542\n","accuracy: 0.511\n","accuracy: 0.511\n","accuracy: 0.588\n","accuracy: 0.554\n","Elapsed time: 2.723 hrs\n","Mean accuracy for cv: 0.541\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"vR9R2Yr_wjLm"},"source":["# Submission"]},{"cell_type":"code","metadata":{"id":"QoTvD36_BxfL"},"source":["import pandas as pd\n","from google.colab import files"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cHyBzYXPfGvQ"},"source":["## bagging"]},{"cell_type":"markdown","metadata":{"id":"_GbqGO0GCu8Y"},"source":["### preparing data"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9_cpI7cDCxMK","executionInfo":{"status":"ok","timestamp":1629212182966,"user_tz":-540,"elapsed":8,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNZwF47kdODsd-L18SA_WiFr15RB65RBmwXBlp=s64","userId":"05018280988882150099"}},"outputId":"d92ce3b2-20d3-4efb-bbe8-54116e779adc"},"source":["train_generator = datagen.flow(train_data, train_label,\n","                            batch_size=4, \n","                            shuffle=True, \n","                            sample_weight=None, \n","                            seed=2021,\n","                            save_to_dir=None, \n","                            save_prefix='', \n","                            save_format='png',\n","                            subset=None,)\n","\n","print('train_data shape: {0}, train_label shape: {1}'.format(train_data.shape, train_label.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["train_data shape: (654, 224, 224, 3), train_label shape: (654, 13)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"xNaLx1UJwjT2","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629212304596,"user_tz":-540,"elapsed":121635,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNZwF47kdODsd-L18SA_WiFr15RB65RBmwXBlp=s64","userId":"05018280988882150099"}},"outputId":"65b27575-0cee-4d89-fb6d-e9455629e0ea"},"source":["# model = creating_vgg_model()\n","# model = creating_resnet_model()\n","# model = creating_efficient_model()\n","model = creating_vit_model()\n","# model = creating_mlp_mixer_model()\n","\n","model.load_weights(str(0)+'model.h5')\n","predicted = model.predict(test_data)\n","table = model.predict(train_generator)\n","table_test = model.predict(test_data)\n","for i in range(1, 5):\n","  model.load_weights(str(i)+'model.h5')\n","  predicted += model.predict(test_data)\n","  table = np.concatenate([table, model.predict(train_generator)], axis=1)\n","  table_test = np.concatenate([table_test, model.predict(test_data)], axis=1)\n","\n","print('predicted shape: {0}'.format(predicted.shape))\n","print('table shape: {0}'.format(table.shape))\n","print('table_test shape: {0}'.format(table_test.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/vit_keras/utils.py:83: UserWarning: Resizing position embeddings from 24, 24 to 14, 14\n","  UserWarning,\n"],"name":"stderr"},{"output_type":"stream","text":["predicted shape: (497, 13)\n","table shape: (654, 65)\n","table_test shape: (497, 65)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"NOyY4f9IBUD7"},"source":["## saving predicted and table"]},{"cell_type":"code","metadata":{"id":"hqRDyfXiA49U"},"source":["PREDICTED_NAME = 'vit'\n","np.save(PREDICTED_NAME+'.npy', predicted)\n","np.save(PREDICTED_NAME+'_for_stacking.npy',table)\n","np.save(PREDICTED_NAME+'_for_stacking_with_test.npy',table_test)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"02WWNjixBZRu"},"source":["## creating csv for submission"]},{"cell_type":"code","metadata":{"id":"DQ2UcOypA4_4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1629212304598,"user_tz":-540,"elapsed":20,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNZwF47kdODsd-L18SA_WiFr15RB65RBmwXBlp=s64","userId":"05018280988882150099"}},"outputId":"7582c4f3-c453-42bf-9f49-51d9fdcee0db"},"source":["predicted = np.argmax(predicted, axis=1)\n","\n","idx = np.arange(1, 498)\n","\n","df = pd.concat([pd.DataFrame(idx, columns=['id']), pd.DataFrame(predicted, columns=['y'])], axis=1)\n","\n","df.to_csv('submission.csv', index=False)\n","\n","df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>id</th>\n","      <th>y</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>11</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>12</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   id   y\n","0   1  12\n","1   2  12\n","2   3  11\n","3   4  11\n","4   5  12"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"code","metadata":{"id":"wPHTdt3IBJiD","colab":{"base_uri":"https://localhost:8080/","height":17},"executionInfo":{"status":"ok","timestamp":1629212304598,"user_tz":-540,"elapsed":11,"user":{"displayName":"Satoru Nakadate","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgNZwF47kdODsd-L18SA_WiFr15RB65RBmwXBlp=s64","userId":"05018280988882150099"}},"outputId":"d612afb7-fa19-4569-baaf-4dc5748e432d"},"source":["files.download(PREDICTED_NAME+'.npy')\n","files.download(PREDICTED_NAME+'_for_stacking.npy')\n","files.download('submission.csv')\n","files.download(PREDICTED_NAME+'_for_stacking_with_test.npy')"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_2f83713f-2521-429d-ad15-7bea3160acb0\", \"vit.npy\", 25972)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_942e2a7a-1889-4854-ada2-364ee2d1e421\", \"vit_for_stacking.npy\", 170168)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_5ddde95a-37de-4517-a223-92c9ae1af276\", \"submission.csv\", 3376)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["\n","    async function download(id, filename, size) {\n","      if (!google.colab.kernel.accessAllowed) {\n","        return;\n","      }\n","      const div = document.createElement('div');\n","      const label = document.createElement('label');\n","      label.textContent = `Downloading \"${filename}\": `;\n","      div.appendChild(label);\n","      const progress = document.createElement('progress');\n","      progress.max = size;\n","      div.appendChild(progress);\n","      document.body.appendChild(div);\n","\n","      const buffers = [];\n","      let downloaded = 0;\n","\n","      const channel = await google.colab.kernel.comms.open(id);\n","      // Send a message to notify the kernel that we're ready.\n","      channel.send({})\n","\n","      for await (const message of channel.messages) {\n","        // Send a message to notify the kernel that we're ready.\n","        channel.send({})\n","        if (message.buffers) {\n","          for (const buffer of message.buffers) {\n","            buffers.push(buffer);\n","            downloaded += buffer.byteLength;\n","            progress.value = downloaded;\n","          }\n","        }\n","      }\n","      const blob = new Blob(buffers, {type: 'application/binary'});\n","      const a = document.createElement('a');\n","      a.href = window.URL.createObjectURL(blob);\n","      a.download = filename;\n","      div.appendChild(a);\n","      a.click();\n","      div.remove();\n","    }\n","  "],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"application/javascript":["download(\"download_01878a1c-9c3d-4c24-a995-32a35e036c47\", \"vit_for_stacking_with_test.npy\", 129348)"],"text/plain":["<IPython.core.display.Javascript object>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"Pe4TYKTFwU3i"},"source":["# Result\n","\n","# CrossEntropy\n","\n","|note|max accuracy(hold-out)|accuracy(cv=10)|LB (hold-out)|LB (bagging)|\n","|:--:|:--:|:--:|:--:|:--:|\n","|VGG16|0.427|-||-|\n","|EfficientNet|0.427|0.477||0.531|\n","|ViT|0.573|-|0.484|0.500|\n","|MLP-Mixer|-|0.469|-|0.578|\n","|ResNet50|0.519|0.523|0.594|0.594|\n","\n","## Focal Loss vs CrossEntropy (VGG16)\n","\n","|note|accuracy (hold-out)|LB|\n","|:--:|:--:|:--:|\n","|crossentropy|0.443|0.438|\n","|focal loss|0.420|0.453|\n","\n","## Focal Loss\n","\n","|note|max accuracy(hold-out)|accuracy(cv=10)|LB (hold-out)|LB (bagging)|\n","|:--:|:--:|:--:|:--:|:--:|\n","|VGG16|-|-|-|-|\n","|ResNet|-|0.486|-|0.531|\n","|EfficientNet|-|0.578|-|0.531|\n","|ViT(b16)|-|0.570|-|0.609|\n","|ViT(l16)|0.588|0.612|-|0.609|\n","|MLP-Mixer|-|-|-|-|\n","|Fine-tunned ResNet|0.511|-|0.391|-|\n","\n","## Preprocessing\n","\n","|note|max accuracy(hold-out)|accuracy (cv=10)|LB (hold-out)|\n","|:--:|:--:|:--:|:--:|\n","|brightness (=0.7), VGG16, Focal Loss|0.450||0.422|\n","|brightness (=0.7), VGG16, Categorical CrossEntropy|0.489||0.359|\n","|brightness (=0.7), vit-l16, Focal Loss||0.576|0.578|\n","|brightness (=0.7), ResNet50, Categorical CrossEntropy|0.473||0.516|"]},{"cell_type":"markdown","metadata":{"id":"Iu0898d-gTzk"},"source":["# End"]}]}